{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc917a7a",
   "metadata": {},
   "source": [
    "### Model Context Protocol\n",
    "\n",
    "El ***Protocolo de Contexto de Modelo** (MCP, por sus siglas en ingl√©s) es un est√°ndar abierto desarrollado por Anthropic que busca estandarizar la forma en que los LLM interact√∫an con fuentes de datos y herramientas externas. MCP permite la integraci√≥n de tools de forma sencilla, escalable y estandarizada y segura.\n",
    "\n",
    "**Componentes de MCP**\n",
    "\n",
    "- **MCP Hosts**: Aplicaciones o entornos donde los usuarios interact√∫an con modelos de IA y desean acceder a datos o herramientas externas a trav√©s de MCP (por ejemplo, Claude Desktop, IDEs, asistentes personalizados).\n",
    "- **MCP Clients**: Componentes ligeros dentro del host que mantienen conexiones 1:1 con servidores MCP, gestionando la comunicaci√≥n y transmisi√≥n de solicitudes y datos.\n",
    "- **MCP Servers**: Programas independientes que exponen capacidades concretas (herramientas, recursos o prompts) a trav√©s del protocolo MCP estandarizado, pudiendo ejecutarse localmente o en la nube.\n",
    "- **Local Data Sources**: Archivos, bases de datos y servicios que residen en el ordenador del usuario y a los que los servidores MCP pueden acceder de forma segura.\n",
    "- **Remote Services**: Sistemas externos accesibles a trav√©s de Internet (por ejemplo, mediante APIs) a los que los servidores MCP pueden conectarse para obtener datos o ejecutar acciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0fac61",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "%%{init: {\"themeVariables\": {\n",
    "  \"fontFamily\": \"Inter, Arial, sans-serif\",\n",
    "  \"clusterBkg\": \"#fff9c4\",\n",
    "  \"clusterBorder\": \"#bdb76b\",\n",
    "  \"clusterTextColor\": \"#000\",\n",
    "  \"nodeTextColor\": \"#000\",\n",
    "  \"nodeBorder\": \"#888\",\n",
    "  \"nodeBkg\": \"#fff\"\n",
    "}}}%%\n",
    "flowchart LR\n",
    "    subgraph local[\"Your Computer\"]\n",
    "        Host[\"Host with MCP Client\\n(Claude, IDEs, Tools)\"]\n",
    "        S1[\"MCP Server A\"]\n",
    "        S2[\"MCP Server B\"]\n",
    "        S3[\"MCP Server C\"]\n",
    "        Host <-->|\"MCP Protocol\"| S1\n",
    "        Host <-->|\"MCP Protocol\"| S2\n",
    "        Host <-->|\"MCP Protocol\"| S3\n",
    "        S1 <--> D1[(\"Local\\nData Source A\")]\n",
    "        S2 <--> D2[(\"Local\\nData Source B\")]\n",
    "    end\n",
    "    subgraph remote[\"Internet\"]\n",
    "        S3 <-->|\"Web APIs\"| D3[(\"Remote\\nService C\")]\n",
    "    end\n",
    "    style local color:#000;\n",
    "    style remote color:#000;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8621a17",
   "metadata": {},
   "source": [
    "### Primer Servidor MCP\n",
    "\n",
    "Vamos a crear un primer servidor MCP que exponga una herramienta simple para sumar dos n√∫meros. Este servidor estar√° implementado en Python utilizando el paquete `FastMCP`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5074fe",
   "metadata": {},
   "source": [
    "Primero creamos el servidor MCP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb461842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/01_FirstMCPServer\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7403e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/01_FirstMCPServer/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/01_FirstMCPServer/server.py\"\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Demo Server\")\n",
    "\n",
    "\n",
    "@mcp.tool(description=\"Add two integers\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ab4f3f",
   "metadata": {},
   "source": [
    "Creamos el cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca32c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/01_FirstMCPServer/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/01_FirstMCPServer/client.py\"\n",
    "import asyncio\n",
    "\n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "\n",
    "\n",
    "async def main():\n",
    "    url = \"http://127.0.0.1:8000/mcp/\"\n",
    "    async with streamablehttp_client(url) as (read, write, get_session_id):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            print(\"Before initialize:\", get_session_id())\n",
    "\n",
    "            await session.initialize()\n",
    "\n",
    "            sid = get_session_id()\n",
    "            print(\"Session ID after initialize:\", sid)\n",
    "\n",
    "            result = await session.call_tool(\"add\", {\"a\": 21, \"b\": 21})\n",
    "            print(\"Server result:\", result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50857c67",
   "metadata": {},
   "source": [
    "Para probar, situarse en el directorio y arrancar el servidor y el cliente en dos terminales diferentes.\n",
    "\n",
    "```python\n",
    "uv run server.py\n",
    "```\n",
    "\n",
    "```python\n",
    "uv run client.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d5613",
   "metadata": {},
   "source": [
    "Tambi√©n podemos ejecutar la tool desde la l√≠nea de comandos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ec9b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/01_FirstMCPServer/script.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/01_FirstMCPServer/script.sh\"\n",
    "#!/usr/bin/env bash\n",
    "set -euo pipefail\n",
    "S=http://127.0.0.1:8000/mcp/\n",
    "ACCEPT='application/json, text/event-stream'\n",
    "CT='application/json'\n",
    "\n",
    "# 1) initialize\n",
    "SID=$(curl -sS -D - -o /dev/null \\\n",
    "  -H \"Accept: $ACCEPT\" -H \"Content-Type: $CT\" \\\n",
    "  -X POST $S \\\n",
    "  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"initialize\",\"params\":{\n",
    "        \"protocolVersion\":\"2025-03-26\",\n",
    "        \"capabilities\":{},\n",
    "        \"clientInfo\":{\"name\":\"bash\",\"version\":\"1.0\"}\n",
    "      }}' | sed -nE 's/^Mcp-Session-Id:[[:space:]]*//Ip' | tr -d '\\r')\n",
    "echo \"SID=$SID\"\n",
    "\n",
    "# 2) notifications/initialized\n",
    "curl -sS \\\n",
    "  -H \"Accept: $ACCEPT\" \\\n",
    "  -H \"Content-Type: $CT\" \\\n",
    "  -H \"Mcp-Session-Id: $SID\" \\\n",
    "  -X POST $S \\\n",
    "  -d '{\"jsonrpc\":\"2.0\",\"method\":\"notifications/initialized\",\"params\":{}}'\n",
    "\n",
    "# 3) tools/call\n",
    "curl -sS \\\n",
    "  -H \"Accept: $ACCEPT\" -H \"Content-Type: $CT\" -H \"Mcp-Session-Id: $SID\" \\\n",
    "  -X POST $S \\\n",
    "  -d '{\"jsonrpc\":\"2.0\",\"id\":2,\"method\":\"tools/call\",\"params\":{\n",
    "        \"name\":\"add\",\"arguments\":{\"a\":2,\"b\":3}}}'\n",
    "echo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c7e68",
   "metadata": {},
   "source": [
    "Adem√°s, podemos probar el servidor MCP desde el inspector de MCP. Para ello, ejecutar en el terminal el siguiente comando.\n",
    "\n",
    "```bash\n",
    "DANGEROUSLY_OMIT_AUTH=true npx @modelcontextprotocol/inspector\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e155b18f",
   "metadata": {},
   "source": [
    "O podemos ejecutar el inspector sin la variable de entorno `DANGEROUSLY_OMIT_AUTH`. En ese caso se ejecutar√≠a as√≠.\n",
    "\n",
    "```bash\n",
    "npx @modelcontextprotocol/inspector\n",
    "```\n",
    "\n",
    "Para poder conectar con el servidor MCP, hay que copiar el valor de la variable `MCP_PROXY_AUTH_TOKEN` que se genera en la l√≠nea de comandos al arrancar el inspector y copiarlo en el inspector pulsado sobre el bot√≥n `Configuration` y pegarlo en la caja `Proxy Session Token`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139cfbd7",
   "metadata": {},
   "source": [
    "Tambi√©n, podemos probar la Tool desde el Chat de Copilot si elegimos el Agente y luego a√±adimos la tool pulsado sobre el icono \"Configurar herramientas\". Actualmente VS Code no soporta el transporte `Streamable HTTP`. Si se desea probar, hay que cambiar el transporte a `SSE` o a `stdio`.Aunque el primero de ellos, est√° obsoleto y no se debe usar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2453a",
   "metadata": {},
   "source": [
    "Por √∫ltimo, se puede configurar el servidor MCP en algunas herramientas de chat como Claude Desktop o Cherry Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3facadea",
   "metadata": {},
   "source": [
    "### Transports\n",
    "\n",
    "MCP utiliza JSON-RPC 2.0 como formato de mensajes. El transporte convierte los mensajes del protocolo MCP a JSON-RPC para transmitirlos y viceversa al recibirlos.\n",
    "\n",
    "Hay tres tipos de mensajes:\n",
    "- **Requests (Solicitudes):** Incluyen m√©todo, par√°metros e identificador.\n",
    "- **Responses (Respuestas):** Devuelven resultados o errores asociados a una solicitud.\n",
    "- **Notifications (Notificaciones):** Mensajes sin respuesta esperada.\n",
    "\n",
    "\n",
    "**Tipos de transporte integrados**\n",
    "\n",
    "Actualmente, MCP define dos mecanismos est√°ndar:\n",
    "\n",
    "1. **Standard Input/Output (stdio):**\n",
    "   - Usa los flujos est√°ndar de entrada y salida del sistema operativo.\n",
    "   - Es √∫til para herramientas de l√≠nea de comandos, integraciones locales y scripts.\n",
    "   - Suele usarse para pruebas en la fase de desarrollo.\n",
    "   - Ejemplo: conectar un cliente o servidor MCP usando procesos locales y stdio[1][3].\n",
    "\n",
    "2. **Streamable HTTP:**\n",
    "   - Utiliza peticiones HTTP POST para la comunicaci√≥n cliente-servidor.\n",
    "   - Opcionalmente, emplea Server-Sent Events (SSE) para transmitir mensajes del servidor al cliente.\n",
    "   - Soporta sesiones con estado, m√∫ltiples clientes concurrentes y conexiones reanudables.\n",
    "   - Permite la persistencia de sesi√≥n mediante un header `Mcp-Session-Id` y la reanudaci√≥n de mensajes perdidos usando `Last-Event-ID`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef9790",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo, se muestra c√≥mo crear un servidor MCP que no usa sesiones. Vemos que el cliente es mucho m√°s sencillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b3edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/02_TransportMethods/streamable_http\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea69ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/02_TransportMethods/streamable_http/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/02_TransportMethods/streamable_http/server.py\"\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Demo Server\", stateless_http=True)\n",
    "\n",
    "\n",
    "@mcp.tool(description=\"Add two integers\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895ab9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/02_TransportMethods/streamable_http/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/02_TransportMethods/streamable_http/client.py\"\n",
    "import asyncio\n",
    "\n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "\n",
    "\n",
    "async def main():\n",
    "    url = \"http://127.0.0.1:8000/mcp/\"\n",
    "    async with streamablehttp_client(url) as (read, write, _):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            # await session.initialize()            # JSON-RPC ‚Äûinitialize‚Äú\n",
    "            result = await session.call_tool(\"add\", {\"a\": 21, \"b\": 21})\n",
    "            print(\"Server result:\", result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0879502",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo se usa el transporte `stdio`. En este caso no se debe arrancar el servidor, ya que se ejecuta el fichero `server.py` directamente desde el cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743fc8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/02_TransportMethods/stdinout\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcda0756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/02_TransportMethods/stdinout/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/02_TransportMethods/stdinout/server.py\"\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Add STDIO Server\")\n",
    "\n",
    "\n",
    "@mcp.tool(description=\"Add two integers\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2552f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/02_TransportMethods/stdinout/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/02_TransportMethods/stdinout/client.py\"\n",
    "import asyncio\n",
    "import sys\n",
    "\n",
    "from mcp import ClientSession\n",
    "from mcp.client.stdio import StdioServerParameters, stdio_client\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    server_params = StdioServerParameters(\n",
    "        command=sys.executable,\n",
    "        args=[\"server.py\"],\n",
    "        env=None,\n",
    "    )\n",
    "\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            res = await session.call_tool(\"add\", {\"a\": 7, \"b\": 5})\n",
    "            print(\"7 + 5 =\", res.content[0].text)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cec0c4",
   "metadata": {},
   "source": [
    "### Componentes MCP: Tools, Resources y Prompts\n",
    "====================================================\n",
    "\n",
    "El Model Context Protocol (MCP) organiza la interacci√≥n entre modelos de lenguaje, aplicaciones y usuarios en tres componentes esenciales, cada uno actuando en un nivel diferente del ecosistema de IA. La imagen proporcionada ilustra c√≥mo estos elementos se conectan y fluyen dentro de una arquitectura t√≠pica MCP.\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    Tools --> LLM\n",
    "    Resources --> Aplicaci√≥n\n",
    "    Prompts --> Usuario\n",
    "\n",
    "    style LLM fill:transparent,stroke-width:0\n",
    "    style Aplicaci√≥n fill:transparent,stroke-width:0\n",
    "    style Usuario fill:transparent,stroke-width:0\n",
    "\n",
    "```\n",
    "\n",
    "**Tools (Herramientas)**\n",
    "\n",
    "Las tools son funciones o acciones que el modelo de lenguaje (LLM) puede invocar directamente. Est√°n dise√±adas para que el modelo ejecute tareas externas como consultar una API, modificar una base de datos o realizar c√°lculos.\n",
    "\n",
    "- Ejemplo: El LLM llama a una tool para buscar informaci√≥n en una base de datos de clientes o para enviar un correo electr√≥nico.\n",
    "\n",
    "**Resources (Recursos)**\n",
    "\n",
    "Los resources representan datos estructurados que la aplicaci√≥n expone al LLM. Son gestionados y controlados por la propia aplicaci√≥n, y sirven como entradas de solo lectura, similares a endpoints GET en una API REST. Incluyen archivos, logs, respuestas de APIs o cualquier fuente de datos relevante.\n",
    "\n",
    "- Ejemplo: La aplicaci√≥n expone logs recientes, archivos de configuraci√≥n o informaci√≥n de usuario como recursos para que el modelo los utilice al responder una consulta.\n",
    "\n",
    "**Prompts (Plantillas)**\n",
    "\n",
    "Los prompts son plantillas reutilizables y predefinidas que estructuran las interacciones entre el usuario y el modelo. Facilitan la estandarizaci√≥n y reutilizaci√≥n de tareas comunes.\n",
    "\n",
    "- Ejemplo: Un usuario selecciona el prompt \"Analizar logs y c√≥digo\", que solicita los archivos y logs relevantes como argumentos, y gu√≠a al modelo a trav√©s de un flujo de an√°lisis estructurado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2852a889",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo, se muestra c√≥mo crear un servidor MCP que expone tools, resources y prompts. Los resources pueden recibir par√°metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb3a3dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/03_RessourcesPromptsTools\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37380090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/03_RessourcesPromptsTools/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/03_RessourcesPromptsTools/server.py\"\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "from mcp.server.fastmcp.prompts import base\n",
    "\n",
    "mcp = FastMCP(\"Recipe-Stateless\", stateless_http=True)\n",
    "\n",
    "_FAKE_DB = {\n",
    "    \"chili_con_carne\": \"Chili con Carne\\n‚Ä¢ Beans\\n‚Ä¢ Ground meat\\n‚Ä¢ Chili\\n‚Ä¶\",\n",
    "    \"pancakes\": \"Pancakes\\n‚Ä¢ Flour\\n‚Ä¢ Milk\\n‚Ä¢ Eggs\\n‚Ä¶\",\n",
    "}\n",
    "\n",
    "\n",
    "@mcp.resource(\"recipes://list\")\n",
    "def list_recipes() -> str:\n",
    "    \"\"\"Returns a comma-separated list of all available recipes.\"\"\"\n",
    "    return \", \".join(sorted(_FAKE_DB))\n",
    "\n",
    "\n",
    "@mcp.resource(\"recipe://{dish}\")\n",
    "def get_recipe(dish: str) -> str:\n",
    "    \"\"\"Returns the recipe for the specified dish.\"\"\"\n",
    "    return _FAKE_DB.get(dish, f\"No recipe found for {dish!r}.\")\n",
    "\n",
    "\n",
    "@mcp.tool(description=\"Doubles an integer.\")\n",
    "def double(n: int) -> int:\n",
    "    return n * 2\n",
    "\n",
    "\n",
    "@mcp.prompt()\n",
    "def review_recipe(recipe: str) -> list[base.Message]:\n",
    "    return [\n",
    "        base.UserMessage(\"Please review this recipe:\"),\n",
    "        base.UserMessage(recipe),\n",
    "    ]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e0cc1",
   "metadata": {},
   "source": [
    "El cliente permite listar las tools, resources y prompts disponibles y utilizarlos. Observe que cuando el listado de resources no incluye los parametrizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a8bc78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/03_RessourcesPromptsTools/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/03_RessourcesPromptsTools/client.py\"\n",
    "import asyncio\n",
    "\n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "\n",
    "SERVER = \"http://127.0.0.1:8000/mcp/\"\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    async with streamablehttp_client(SERVER) as (read, write, _):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            resources = await session.list_resources()\n",
    "            print(\"Resources:\", [r.uri for r in resources.resources])\n",
    "\n",
    "            tools = await session.list_tools()\n",
    "            print(\"Tools:\", [t.name for t in tools.tools])\n",
    "\n",
    "            prompts = await session.list_prompts()\n",
    "            print(\"Prompts:\", prompts.prompts)\n",
    "\n",
    "            recipe_response = await session.read_resource(\"recipe://chili_con_carne\")\n",
    "            recipe_text = recipe_response.contents[0].text\n",
    "            print(\"\\nRecipe:\\n\", recipe_text)\n",
    "\n",
    "            doubled_response = await session.call_tool(\"double\", {\"n\": 21})\n",
    "            doubled_value = doubled_response.content[0].text\n",
    "            print(f\"\\n21 doubled -> {doubled_value}\")\n",
    "\n",
    "            prompt_response = await session.get_prompt(\n",
    "                \"review_recipe\",\n",
    "                {\"recipe\": recipe_text},\n",
    "            )\n",
    "            print(\"\\nPrompt messages:\")\n",
    "            for message in prompt_response.messages:\n",
    "                print(f\"[{message.role}] {message.content.text}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb0959",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "El contexto en MCP permite que el servidor comunique informaci√≥n al cliente durante la ejecuci√≥n de una solicitud. Esto es √∫til para proporcionar datos adicionales o resultados intermedios que el cliente puede necesitar para completar la tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399b454",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo, el servidor simula el procesamiento de una lista de elementos y la comunicaci√≥n al cliente durante la ejecuci√≥n de una solicitud. Observe que el cliente recibe dos tipos de mensajes: uno de tipo log y otro de tipo progress.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1e536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/04_Context\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a240fb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/04_Context/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/04_Context/server.py\"\n",
    "import asyncio\n",
    "\n",
    "from mcp.server.fastmcp import Context, FastMCP\n",
    "\n",
    "mcp = FastMCP(\n",
    "    name=\"ProgressDemoServer\",\n",
    "    stateless_http=False,\n",
    ")\n",
    "\n",
    "\n",
    "@mcp.tool(\n",
    "    name=\"process_items\", description=\"Processes a list of items with progress updates\"\n",
    ")\n",
    "async def process_items(items: list[str], ctx: Context) -> list[str]:\n",
    "    total = len(items)\n",
    "    results: list[str] = []\n",
    "    for i, item in enumerate(items, start=1):\n",
    "        await ctx.info(f\"Processing item {i}/{total}: {item}\")\n",
    "        await ctx.report_progress(progress=i, total=total)\n",
    "        await asyncio.sleep(0.5)\n",
    "        results.append(item.upper())\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed183a",
   "metadata": {},
   "source": [
    "El cliente usa un `handler` para cada uno de los tipos de mensajes enviados por el servidor. Observe tambi√©n que se ha usado el paquete `fastmcp` en lugar de `mcp`, ya que no se ha conseguido que el paquete `mcp` funcione correctamente con context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dac07dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/04_Context/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/04_Context/client.py\"\n",
    "import asyncio\n",
    "\n",
    "import mcp.types as types\n",
    "from fastmcp import Client\n",
    "from fastmcp.client.logging import LogMessage\n",
    "from fastmcp.client.transports import StreamableHttpTransport\n",
    "\n",
    "\n",
    "async def message_handler(msg):\n",
    "    if not isinstance(msg, types.ServerNotification):\n",
    "        return\n",
    "\n",
    "    root = msg.root\n",
    "    if isinstance(root, types.ProgressNotification):\n",
    "        p = root.params\n",
    "        print(f\"[Progress] {p.progress}/{p.total or '?'}\")\n",
    "\n",
    "\n",
    "async def log_handler(params: LogMessage):\n",
    "    level = params.level.upper()\n",
    "    print(f\"[Log ‚Äì {level}] {params.data}\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    transport = StreamableHttpTransport(url=\"http://127.0.0.1:8000/mcp/\")\n",
    "    client = Client(transport, message_handler=message_handler, log_handler=log_handler)\n",
    "\n",
    "    async with client:\n",
    "        tools = await client.list_tools()\n",
    "        print(\"‚Üí Available tools:\", [t.name for t in tools])\n",
    "\n",
    "        print(\"‚Üí Calling process_items‚Ä¶\")\n",
    "        items = [\"one\", \"two\", \"three\", \"four\", \"five\"]\n",
    "        result = await client.call_tool(\"process_items\", {\"items\": items})\n",
    "        processed = [c.text for c in result]\n",
    "        print(\"‚Üí Result:\", processed)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7546d2f",
   "metadata": {},
   "source": [
    "### Tools din√°micas\n",
    "\n",
    "En ocasiones, es necesario que el servidor MCP pueda exponer tools din√°micamente, es decir, que el cliente pueda solicitar al servidor que le env√≠e una tool espec√≠fica en lugar de tener que conocerla de antemano. Esto es √∫til cuando las tools dependen de datos espec√≠ficos o del contexto de la solicitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b1f5a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/05_Discovery\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0580f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/05_Discovery/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/05_Discovery/server.py\"\n",
    "import asyncio\n",
    "import re\n",
    "from fastmcp.tools import Tool\n",
    "from typing import Callable\n",
    "from fastmcp import Context, FastMCP\n",
    "\n",
    "mcp = FastMCP(name=\"Dynamic-Tool-Router Demo\")\n",
    "\n",
    "\n",
    "async def to_upper(text: str) -> str:\n",
    "    return text.upper()\n",
    "\n",
    "\n",
    "async def count_words(text: str) -> int:\n",
    "    await asyncio.sleep(0)\n",
    "    return len(re.findall(r\"\\w+\", text))\n",
    "\n",
    "\n",
    "TOOLS: dict[str, tuple[Callable, str, str]] = {\n",
    "    \"uppercase\": (to_upper, \"upper_tool\", \"Convert text to uppercase.\"),\n",
    "    \"wordcount\": (count_words, \"wordcount_tool\", \"Count words in the text.\"),\n",
    "}\n",
    "\n",
    "\n",
    "def classify(text: str) -> str | None:\n",
    "    if re.fullmatch(r\"[A-Z√Ñ√ñ√ú√ä·∫û ]+\", text):\n",
    "        return \"wordcount\"\n",
    "    if \"words\" in text.lower() or \"count\" in text.lower():\n",
    "        return \"wordcount\"\n",
    "    if text.islower() or \"upper\" in text.lower():\n",
    "        return \"uppercase\"\n",
    "    return None\n",
    "\n",
    "\n",
    "@mcp.tool(\n",
    "    name=\"router\",\n",
    "    description=\"Classifies text, registers the appropriate tool, executes it, and returns the result.\",\n",
    ")\n",
    "async def router(text: str, ctx: Context):\n",
    "    category = classify(text) or \"uppercase\"\n",
    "    fn, tool_name, desc = TOOLS[category]\n",
    "\n",
    "    # >= 2.7.0\n",
    "    new_tool = Tool.from_function(fn, name=tool_name, description=desc)\n",
    "    ctx.fastmcp.add_tool(new_tool)\n",
    "\n",
    "    # ctx.fastmcp.add_tool(fn, name=tool_name, description=desc) # before 2.7.0\n",
    "    result = await fn(text)\n",
    "    await ctx.info(f\"Result from {tool_name}: {result!r}\")\n",
    "    # await ctx.fastmcp.remove_tool(tool_name)  # remove the tool again if desired\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df4315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools BEFORE : ['router', 'upper_tool']\n",
      "Response   : [TextContent(type='text', text='PLEASE MAKE THIS UPPER CASE', annotations=None)]\n",
      "Tools AFTER  : ['router', 'upper_tool']\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/05_Discovery/client.py\"\n",
    "import asyncio\n",
    "from fastmcp import Client\n",
    "from fastmcp.client.transports import StreamableHttpTransport\n",
    "\n",
    "async def main():\n",
    "    async with Client(StreamableHttpTransport(\"http://127.0.0.1:8000/mcp/\")) as c:\n",
    "        print(\"Tools BEFORE :\", [t.name for t in await c.list_tools()])\n",
    "        response = await c.call_tool(\"router\", {\"text\": \"please make this upper CASE\"})\n",
    "        print(\"Response   :\", response)\n",
    "        print(\"Tools AFTER  :\", [t.name for t in await c.list_tools()])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48428edd",
   "metadata": {},
   "source": [
    "### Integraci√≥n con LangChain\n",
    "\n",
    "Un agente de LangChain puede usar las tools de un servidor MCP como si fueran tools de LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1361aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/08_LangChain_MCP\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8315226e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/08_LangChain_MCP/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/08_LangChain_MCP/server.py\"\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(name=\"WeatherServer\", stateless_http=True)\n",
    "\n",
    "\n",
    "@mcp.tool(\n",
    "    name=\"get_weather\",\n",
    "    description=\"Returns a weather description for a given city\",\n",
    ")\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        city (str): Name of the city\n",
    "    Returns:\n",
    "        str: Description of the current weather (mock data)\n",
    "    \"\"\"\n",
    "    return \"Sunny, 22¬∞C\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\", host=\"127.0.0.1\", port=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886703db",
   "metadata": {},
   "source": [
    "Podr√≠amos haber guardado el cliente como hemos hecho en los anteriores ejemplos, aunque en este caso se ha preferido ejecutarlo directamente desde Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae5fe1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/surtich/projects/IA para desarrolladores/.env\n",
      "Human: ¬øCu√°l es el clima en Madrid?\n",
      "AI calls: [{'name': 'get_weather', 'args': {'city': 'Madrid'}, 'id': '7af79f6d-b491-4aed-a06a-4951157907dc', 'type': 'tool_call'}]\n",
      "Tool: Sunny, 22¬∞C\n",
      "AI: El clima en Madrid es soleado, con una temperatura de 22¬∞C.\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "# Busca el archivo .env (o el que especifiques) en el directorio actual y padres\n",
    "dotenv_path = dotenv.find_dotenv()\n",
    "print(dotenv_path)  # Imprime la ruta completa al archivo encontrado\n",
    "\n",
    "# Carga las variables de entorno desde ese archivo\n",
    "dotenv.load_dotenv(dotenv_path)\n",
    "\n",
    "async def main():\n",
    "    client = MultiServerMCPClient(\n",
    "        {\n",
    "            \"weather\": {\n",
    "                \"transport\": \"streamable_http\",\n",
    "                \"url\": \"http://127.0.0.1:3000/mcp/\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    model = ChatGoogleGenerativeAI(\n",
    "       model=\"gemini-2.5-flash\",\n",
    "        api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    )\n",
    "    tools = await client.get_tools()\n",
    "    agent_executor = create_react_agent(model, tools)\n",
    "    messages = await agent_executor.ainvoke({\"messages\": [\"¬øCu√°l es el clima en Madrid?\"]})\n",
    "    for message in messages[\"messages\"]:\n",
    "        if isinstance(message, AIMessage):\n",
    "            if message.tool_calls:\n",
    "                print(f\"AI calls: {message.tool_calls}\")\n",
    "            else:\n",
    "                print(f\"AI: {message.content}\")\n",
    "        elif isinstance(message, HumanMessage):\n",
    "            print(f\"Human: {message.content}\")\n",
    "        elif isinstance(message, ToolMessage):\n",
    "            print(f\"Tool: {message.content}\")\n",
    "        else:\n",
    "            print(f\"Message: {message.content}\")\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd89714",
   "metadata": {},
   "source": [
    "### Integraci√≥n con OpenAI SDK Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "757a52f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "El tiempo en Madrid es soleado, 22¬∞C."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from agents import Agent, ModelSettings, OpenAIChatCompletionsModel, Runner\n",
    "from agents.mcp import MCPServerStreamableHttp\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "chat_client = AsyncOpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "chat_model = OpenAIChatCompletionsModel(model=\"gemini-2.5-flash\", openai_client=chat_client)\n",
    "\n",
    "async with MCPServerStreamableHttp(    name=\"weather\",\n",
    "    params={\"url\": \"http://127.0.0.1:3000/mcp\"}\n",
    ") as weather_server:\n",
    "\n",
    "    chat_agent = Agent(\n",
    "        name=\"Agente MCP\",\n",
    "        mcp_servers=[weather_server],\n",
    "        model=chat_model,\n",
    "        model_settings=ModelSettings(tool_choice=\"required\"),\n",
    "    )\n",
    "\n",
    "    result = await Runner.run(chat_agent, \"¬øQu√© tiempo hace en Madrid?\")\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b2694",
   "metadata": {},
   "source": [
    "### Autenticaci√≥n con OAuth2\n",
    "\n",
    "Los servidores MCP permiten autenticaci√≥n de clientes MCP utilizando el protocolo OAuth2. La autenticaci√≥n se hace a nivel de cliente, no de usuario. Para ello se requiere un servidor OAuth de autentificaci√≥n (GitHub, Google, auth0, ...). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f927e27b",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant Cliente as ü§ñ Cliente\n",
    "    participant ServidorAuth as Servidor de Autorizaci√≥n\n",
    "    participant ServidorMCP as Servidor MCP\n",
    "\n",
    "    Cliente->>ServidorAuth: 1. Solicita token de acceso\n",
    "    ServidorAuth-->>Cliente: 2. Devuelve JWT (token)\n",
    "    Cliente->>ServidorMCP: 3. Usa token en cabecera HTTP para llamar a la tool\n",
    "    ServidorMCP->>ServidorAuth: 4. Valida el token (incluyendo \"scope\")\n",
    "    ServidorMCP-->>Cliente: 5. El cliente recibe la respuesta del servidor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb7243",
   "metadata": {},
   "source": [
    "Para registrar una nueva API y aplicaci√≥n cliente en Auth0:\n",
    "\n",
    "1.- Registrarse e ir al [`Dashboard`](https://manage.auth0.com/dashboard) de Auth0.\n",
    "2.- Pulsar sobre `Applications` en el men√∫ de la izquierda.\n",
    "3.- Pulsar sobre `APIs`.\n",
    "4.- Pulsar sobre `+ Create API`.\n",
    "5.- Introducir un nombre y una descripci√≥n para la API.\n",
    "6.- En `Identifier`, introducir: `http://localhost:8000/mcp`.\n",
    "7.- Pulsar  sobre `Create`.\n",
    "8.- Pulsar sobre `Permissions`.\n",
    "9.- A√±adir un nuevo permiso con el nombre `read:add` y la descripci√≥n `Permite usar tool read del servidor MCP`.\n",
    "10.- Pulsar sobre `Machine to Machine Applications`.\n",
    "11.- Seleccionar el permiso y pulsar `Update` y `Continue`.\n",
    "12.- Pulsar sobre `Applications` en el men√∫ de la izquierda.\n",
    "13.- Seleccionar la aplicaci√≥n que se ha creado.\n",
    "14.- Copiar `DOMAIN`, `Client ID` y `Client Secret` que se han generado en el fichero `.env` con los nombres de variables `AUTH0_DOMAIN`, `AUTH0_CLIENT_ID` y `AUTH0_CLIENT_SECRET`, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4136950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/09_Authorization\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7442866f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/09_Authorization/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/09_Authorization/server.py\"\n",
    "import os\n",
    "\n",
    "from fastmcp import FastMCP\n",
    "from fastmcp.server.auth.providers.bearer import BearerAuthProvider\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "AUTH0_DOMAIN = os.environ[\"AUTH0_DOMAIN\"]\n",
    "API_AUDIENCE = os.environ.get(\"API_AUDIENCE\", \"http://localhost:8000/mcp\")\n",
    "REQUIRED_SCOPES = [\"read:add\"]\n",
    "\n",
    "auth = BearerAuthProvider(\n",
    "    jwks_uri=f\"{AUTH0_DOMAIN.rstrip('/')}/.well-known/jwks.json\",\n",
    "    issuer=AUTH0_DOMAIN.rstrip(\"/\") + \"/\",\n",
    "    audience=API_AUDIENCE,\n",
    "    required_scopes=REQUIRED_SCOPES,\n",
    ")\n",
    "\n",
    "mcp = FastMCP(\n",
    "    name=\"SecureAddServer\",\n",
    "    stateless_http=True,\n",
    "    auth=auth,\n",
    ")\n",
    "\n",
    "\n",
    "@mcp.tool(description=\"Add two integers\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\", host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8874279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/09_Authorization/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/09_Authorization/client.py\"\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "import httpx\n",
    "from fastmcp import Client\n",
    "from fastmcp.client.transports import StreamableHttpTransport\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv \n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "AUTH0_DOMAIN = os.environ[\"AUTH0_DOMAIN\"]\n",
    "AUTH0_CLIENT_ID = os.environ[\"AUTH0_CLIENT_ID\"]\n",
    "AUTH0_CLIENT_SECRET = os.environ[\"AUTH0_CLIENT_SECRET\"]\n",
    "API_AUDIENCE = \"http://localhost:8000/mcp\"\n",
    "\n",
    "async def get_auth0_token() -> str:\n",
    "    \"\"\"\n",
    "    Request an access token from Auth0 using the Client Credentials Grant.\n",
    "    \"\"\"\n",
    "    token_url = f\"{AUTH0_DOMAIN}/oauth/token\"\n",
    "    payload = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": AUTH0_CLIENT_ID,\n",
    "        \"client_secret\": AUTH0_CLIENT_SECRET,\n",
    "        \"audience\": API_AUDIENCE,\n",
    "    }\n",
    "    async with httpx.AsyncClient() as http:\n",
    "        response = await http.post(token_url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data[\"access_token\"]\n",
    "\n",
    "\n",
    "async def main():\n",
    "    token = await get_auth0_token()\n",
    "    print(\"Got Auth0 token:\", token)\n",
    "\n",
    "    transport = StreamableHttpTransport(\n",
    "        url=API_AUDIENCE, headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "    )\n",
    "\n",
    "    client = Client(transport)\n",
    "    async with client:\n",
    "        result = await client.call_tool(\"add\", {\"a\": 5, \"b\": 7})\n",
    "        print(\"5 + 7 =\", result[0].text)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e71ae",
   "metadata": {},
   "source": [
    "Se puede probar desde el inspector de MCP a√±adiendo el Bearer Token en la configuraci√≥n del inspector. Para obtener el token, en el `Dashboard` de Auth0, pulsar sobre `Applications` y luego sobre selecci√≥n la aplicaci√≥n; pulsar sobre `Quickstart` y con la pesta√±a `CURL` seleccionada, pulsar `Get Token`. Copiar el token que se genera y pegarlo en el inspector en la cada `Bearer` (pulsar `Authentication` para ver la caja)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a608af",
   "metadata": {},
   "source": [
    "### Integraci√≥n con FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38216105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/10_Fastapi_Integration\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb68575",
   "metadata": {},
   "source": [
    "Observe que se puede definir endpoints de FastAPI y tools de MCP. Los endpoints de FastAPI se usan como `tools` de MCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96481387",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"25_MCP/10_Fastapi_Integration/server.py\"\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastmcp import FastMCP\n",
    "from pydantic import BaseModel\n",
    "\n",
    "app = FastAPI(title=\"Product API\")\n",
    "_products: dict[int, dict] = {}\n",
    "\n",
    "class Product(BaseModel):\n",
    "    name: str\n",
    "    price: float\n",
    "\n",
    "@app.get(\"/products\")\n",
    "def list_products():\n",
    "    \"\"\"List all products\"\"\"\n",
    "    return list(_products.values())\n",
    "\n",
    "@app.get(\"/products/{product_id}\")\n",
    "def get_product(product_id: int):\n",
    "    \"\"\"Get a product by its ID\"\"\"\n",
    "    if product_id not in _products:\n",
    "        raise HTTPException(status_code=404, detail=\"Product not found\")\n",
    "    return _products[product_id]\n",
    "\n",
    "@app.post(\"/products\")\n",
    "def create_product(p: Product):\n",
    "    \"\"\"Create a new product\"\"\"\n",
    "    new_id = len(_products) + 1\n",
    "    _products[new_id] = {\"id\": new_id, **p.model_dump()}\n",
    "    return _products[new_id]\n",
    "\n",
    "mcp = FastMCP.from_fastapi(app=app, name=\"ProductMCP\")\n",
    "\n",
    "@mcp.tool(description=\"Add two integers\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\", host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5b215dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/10_Fastapi_Integration/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/10_Fastapi_Integration/client.py\"\n",
    "import asyncio\n",
    "from fastmcp import Client\n",
    "from fastmcp.client.transports import StreamableHttpTransport\n",
    "\n",
    "SERVER = \"http://127.0.0.1:8000/mcp/\"\n",
    "\n",
    "\n",
    "def section(title: str):\n",
    "    print(f\"\\n{'=' * 10} {title} {'=' * 10}\")\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    async with Client(StreamableHttpTransport(SERVER)) as session:\n",
    "        \n",
    "        tools = await session.list_tools()\n",
    "        section(\"Available Tools\")\n",
    "        for tool in tools:\n",
    "            print(f\"Tool Name: {tool.name}\")\n",
    "        \n",
    "        all_products = await session.call_tool(tools[0].name)\n",
    "        section(\"All Products (Before)\")\n",
    "        print(all_products)\n",
    "\n",
    "\n",
    "        create_tool_name = tools[1].name\n",
    "\n",
    "        section(f\"Calling Tool: {create_tool_name}\")\n",
    "        created = await session.call_tool(\n",
    "            create_tool_name,\n",
    "            {\"name\": \"Widget\", \"price\": 19.99},\n",
    "        )\n",
    "        print(\"Created product:\", created[0].text)\n",
    "\n",
    "        all_products = await session.call_tool(tools[0].name)\n",
    "        section(\"All Products (After)\")\n",
    "        print(all_products)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad833f",
   "metadata": {},
   "source": [
    "Otra forma de integrar FastAPI con MCP se muestra en el siguiente c√≥digo. En este caso, los endpoint de FastAPI se sirven desde fuera de MCP. MCP est√° montado en `http://localhost:8000/mcp-server/mcp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c39a8d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/10_Fastapi_Integration/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/10_Fastapi_Integration/server.py\"\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastmcp import FastMCP\n",
    "from pydantic import BaseModel\n",
    "\n",
    "_products: dict[int, dict] = {}\n",
    "\n",
    "mcp = FastMCP(\"AddServer\", stateless_http=True)\n",
    "mcp_app = mcp.http_app(path=\"/mcp\")\n",
    "app = FastAPI(lifespan=mcp_app.router.lifespan_context)\n",
    "app.mount(\"/mcp-server\", mcp_app)\n",
    "\n",
    "class Product(BaseModel):\n",
    "    name: str\n",
    "    price: float\n",
    "\n",
    "\n",
    "@app.get(\"/products\")\n",
    "def list_products():\n",
    "    \"\"\"List all products\"\"\"\n",
    "    return list(_products.values())\n",
    "\n",
    "\n",
    "@app.get(\"/products/{product_id}\")\n",
    "def get_product(product_id: int):\n",
    "    \"\"\"Get a product by its ID\"\"\"\n",
    "    if product_id not in _products:\n",
    "        raise HTTPException(status_code=404, detail=\"Product not found\")\n",
    "    return _products[product_id]\n",
    "\n",
    "\n",
    "@app.post(\"/products\")\n",
    "def create_product(p: Product):\n",
    "    \"\"\"Create a new product\"\"\"\n",
    "    new_id = len(_products) + 1\n",
    "    _products[new_id] = {\"id\": new_id, **p.model_dump()}\n",
    "    return _products[new_id]\n",
    "\n",
    "\n",
    "@mcp.tool(description=\"Add two integers\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app=app, host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e380c27",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia-para-desarrolladores",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc917a7a",
   "metadata": {},
   "source": [
    "### Model Context Protocol\n",
    "\n",
    "El ***Protocolo de Contexto de Modelo** (MCP, por sus siglas en inglés) es un estándar abierto desarrollado por Anthropic que busca estandarizar la forma en que los LLM interactúan con fuentes de datos y herramientas externas. MCP permite la integración de tools de forma sencilla, escalable y estandarizada y segura.\n",
    "\n",
    "**Componentes de MCP**\n",
    "\n",
    "- **MCP Hosts**: Aplicaciones o entornos donde los usuarios interactúan con modelos de IA y desean acceder a datos o herramientas externas a través de MCP (por ejemplo, Claude Desktop, IDEs, asistentes personalizados).\n",
    "- **MCP Clients**: Componentes ligeros dentro del host que mantienen conexiones 1:1 con servidores MCP, gestionando la comunicación y transmisión de solicitudes y datos.\n",
    "- **MCP Servers**: Programas independientes que exponen capacidades concretas (herramientas, recursos o prompts) a través del protocolo MCP estandarizado, pudiendo ejecutarse localmente o en la nube.\n",
    "- **Local Data Sources**: Archivos, bases de datos y servicios que residen en el ordenador del usuario y a los que los servidores MCP pueden acceder de forma segura.\n",
    "- **Remote Services**: Sistemas externos accesibles a través de Internet (por ejemplo, mediante APIs) a los que los servidores MCP pueden conectarse para obtener datos o ejecutar acciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0fac61",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "%%{init: {\"themeVariables\": {\n",
    "  \"fontFamily\": \"Inter, Arial, sans-serif\",\n",
    "  \"clusterBkg\": \"#fff9c4\",\n",
    "  \"clusterBorder\": \"#bdb76b\",\n",
    "  \"clusterTextColor\": \"#000\",\n",
    "  \"nodeTextColor\": \"#000\",\n",
    "  \"nodeBorder\": \"#888\",\n",
    "  \"nodeBkg\": \"#fff\"\n",
    "}}}%%\n",
    "flowchart LR\n",
    "    subgraph local[\"Your Computer\"]\n",
    "        Host[\"Host with MCP Client\\n(Claude, IDEs, Tools)\"]\n",
    "        S1[\"MCP Server A\"]\n",
    "        S2[\"MCP Server B\"]\n",
    "        S3[\"MCP Server C\"]\n",
    "        Host <-->|\"MCP Protocol\"| S1\n",
    "        Host <-->|\"MCP Protocol\"| S2\n",
    "        Host <-->|\"MCP Protocol\"| S3\n",
    "        S1 <--> D1[(\"Local\\nData Source A\")]\n",
    "        S2 <--> D2[(\"Local\\nData Source B\")]\n",
    "    end\n",
    "    subgraph remote[\"Internet\"]\n",
    "        S3 <-->|\"Web APIs\"| D3[(\"Remote\\nService C\")]\n",
    "    end\n",
    "    style local color:#000;\n",
    "    style remote color:#000;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8621a17",
   "metadata": {},
   "source": [
    "### Primer Servidor MCP\n",
    "\n",
    "Vamos a crear un primer servidor MCP que exponga una herramienta simple para sumar dos números. Este servidor estará implementado en Python utilizando el paquete `FastMCP`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5074fe",
   "metadata": {},
   "source": [
    "Primero creamos el servidor MCP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb461842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/01_FirstMCPServer\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7403e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/01_FirstMCPServer/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/01_FirstMCPServer/server.py\"\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Demo Server\")\n",
    "\n",
    "\n",
    "@mcp.tool(description=\"Add two integers\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ab4f3f",
   "metadata": {},
   "source": [
    "Creamos el cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca32c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/01_FirstMCPServer/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/01_FirstMCPServer/client.py\"\n",
    "import asyncio\n",
    "\n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "\n",
    "\n",
    "async def main():\n",
    "    url = \"http://127.0.0.1:8000/mcp/\"\n",
    "    async with streamablehttp_client(url) as (read, write, get_session_id):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            print(\"Before initialize:\", get_session_id())\n",
    "\n",
    "            await session.initialize()\n",
    "\n",
    "            sid = get_session_id()\n",
    "            print(\"Session ID after initialize:\", sid)\n",
    "\n",
    "            result = await session.call_tool(\"add\", {\"a\": 21, \"b\": 21})\n",
    "            print(\"Server result:\", result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50857c67",
   "metadata": {},
   "source": [
    "Para probar, situarse en el directorio y arrancar el servidor y el cliente en dos terminales diferentes.\n",
    "\n",
    "```python\n",
    "uv run server.py\n",
    "```\n",
    "\n",
    "```python\n",
    "uv run client.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d5613",
   "metadata": {},
   "source": [
    "También podemos ejecutar la tool desde la línea de comandos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ec9b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/01_FirstMCPServer/script.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/01_FirstMCPServer/script.sh\"\n",
    "#!/usr/bin/env bash\n",
    "set -euo pipefail\n",
    "S=http://127.0.0.1:8000/mcp/\n",
    "ACCEPT='application/json, text/event-stream'\n",
    "CT='application/json'\n",
    "\n",
    "# 1) initialize\n",
    "SID=$(curl -sS -D - -o /dev/null \\\n",
    "  -H \"Accept: $ACCEPT\" -H \"Content-Type: $CT\" \\\n",
    "  -X POST $S \\\n",
    "  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"initialize\",\"params\":{\n",
    "        \"protocolVersion\":\"2025-03-26\",\n",
    "        \"capabilities\":{},\n",
    "        \"clientInfo\":{\"name\":\"bash\",\"version\":\"1.0\"}\n",
    "      }}' | sed -nE 's/^Mcp-Session-Id:[[:space:]]*//Ip' | tr -d '\\r')\n",
    "echo \"SID=$SID\"\n",
    "\n",
    "# 2) notifications/initialized\n",
    "curl -sS \\\n",
    "  -H \"Accept: $ACCEPT\" \\\n",
    "  -H \"Content-Type: $CT\" \\\n",
    "  -H \"Mcp-Session-Id: $SID\" \\\n",
    "  -X POST $S \\\n",
    "  -d '{\"jsonrpc\":\"2.0\",\"method\":\"notifications/initialized\",\"params\":{}}'\n",
    "\n",
    "# 3) tools/call\n",
    "curl -sS \\\n",
    "  -H \"Accept: $ACCEPT\" -H \"Content-Type: $CT\" -H \"Mcp-Session-Id: $SID\" \\\n",
    "  -X POST $S \\\n",
    "  -d '{\"jsonrpc\":\"2.0\",\"id\":2,\"method\":\"tools/call\",\"params\":{\n",
    "        \"name\":\"add\",\"arguments\":{\"a\":2,\"b\":3}}}'\n",
    "echo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c7e68",
   "metadata": {},
   "source": [
    "Además, podemos probar el servidor MCP desde el inspector de MCP. Para ello, ejecutar en el terminal el siguiente comando.\n",
    "\n",
    "```bash\n",
    "DANGEROUSLY_OMIT_AUTH=true npx @modelcontextprotocol/inspector\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e155b18f",
   "metadata": {},
   "source": [
    "O podemos ejecutar el inspector sin la variable de entorno `DANGEROUSLY_OMIT_AUTH`. En ese caso se ejecutaría así.\n",
    "\n",
    "```bash\n",
    "npx @modelcontextprotocol/inspector\n",
    "```\n",
    "\n",
    "Para poder conectar con el servidor MCP, hay que copiar el valor de la variable `MCP_PROXY_AUTH_TOKEN` que se genera en la línea de comandos al arrancar el inspector y copiarlo en el inspector pulsado sobre el botón `Configuration` y pegarlo en la caja `Proxy Session Token`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139cfbd7",
   "metadata": {},
   "source": [
    "También, podemos probar la Tool desde el Chat de Copilot si elegimos el Agente y luego añadimos la tool pulsado sobre el icono \"Configurar herramientas\". Actualmente VS Code no soporta el transporte `Streamable HTTP`. Si se desea probar, hay que cambiar el transporte a `SSE` o a `stdio`.Aunque el primero de ellos, está obsoleto y no se debe usar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2453a",
   "metadata": {},
   "source": [
    "Por último, se puede configurar el servidor MCP en algunas herramientas de chat como Claude Desktop o Cherry Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3facadea",
   "metadata": {},
   "source": [
    "### Transports\n",
    "\n",
    "MCP utiliza JSON-RPC 2.0 como formato de mensajes. El transporte convierte los mensajes del protocolo MCP a JSON-RPC para transmitirlos y viceversa al recibirlos.\n",
    "\n",
    "Hay tres tipos de mensajes:\n",
    "- **Requests (Solicitudes):** Incluyen método, parámetros e identificador.\n",
    "- **Responses (Respuestas):** Devuelven resultados o errores asociados a una solicitud.\n",
    "- **Notifications (Notificaciones):** Mensajes sin respuesta esperada.\n",
    "\n",
    "\n",
    "**Tipos de transporte integrados**\n",
    "\n",
    "Actualmente, MCP define dos mecanismos estándar:\n",
    "\n",
    "1. **Standard Input/Output (stdio):**\n",
    "   - Usa los flujos estándar de entrada y salida del sistema operativo.\n",
    "   - Es útil para herramientas de línea de comandos, integraciones locales y scripts.\n",
    "   - Suele usarse para pruebas en la fase de desarrollo.\n",
    "   - Ejemplo: conectar un cliente o servidor MCP usando procesos locales y stdio[1][3].\n",
    "\n",
    "2. **Streamable HTTP:**\n",
    "   - Utiliza peticiones HTTP POST para la comunicación cliente-servidor.\n",
    "   - Opcionalmente, emplea Server-Sent Events (SSE) para transmitir mensajes del servidor al cliente.\n",
    "   - Soporta sesiones con estado, múltiples clientes concurrentes y conexiones reanudables.\n",
    "   - Permite la persistencia de sesión mediante un header `Mcp-Session-Id` y la reanudación de mensajes perdidos usando `Last-Event-ID`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef9790",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo, se muestra cómo crear un servidor MCP que no usa sesiones. Vemos que el cliente es mucho más sencillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b3edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/02_TransportMethods/streamable_http\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea69ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/02_TransportMethods/streamable_http/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/02_TransportMethods/streamable_http/server.py\"\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Demo Server\", stateless_http=True)\n",
    "\n",
    "\n",
    "@mcp.tool(description=\"Add two integers\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895ab9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/02_TransportMethods/streamable_http/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/02_TransportMethods/streamable_http/client.py\"\n",
    "import asyncio\n",
    "\n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "\n",
    "\n",
    "async def main():\n",
    "    url = \"http://127.0.0.1:8000/mcp/\"\n",
    "    async with streamablehttp_client(url) as (read, write, _):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            # await session.initialize()            # JSON-RPC „initialize“\n",
    "            result = await session.call_tool(\"add\", {\"a\": 21, \"b\": 21})\n",
    "            print(\"Server result:\", result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0879502",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo se usa el transporte `stdio`. En este caso no se debe arrancar el servidor, ya que se ejecuta el fichero `server.py` directamente desde el cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743fc8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/02_TransportMethods/stdinout\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcda0756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/02_TransportMethods/stdinout/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/02_TransportMethods/stdinout/server.py\"\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Add STDIO Server\")\n",
    "\n",
    "\n",
    "@mcp.tool(description=\"Add two integers\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2552f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/02_TransportMethods/stdinout/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/02_TransportMethods/stdinout/client.py\"\n",
    "import asyncio\n",
    "import sys\n",
    "\n",
    "from mcp import ClientSession\n",
    "from mcp.client.stdio import StdioServerParameters, stdio_client\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    server_params = StdioServerParameters(\n",
    "        command=sys.executable,\n",
    "        args=[\"server.py\"],\n",
    "        env=None,\n",
    "    )\n",
    "\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            res = await session.call_tool(\"add\", {\"a\": 7, \"b\": 5})\n",
    "            print(\"7 + 5 =\", res.content[0].text)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cec0c4",
   "metadata": {},
   "source": [
    "### Componentes MCP: Tools, Resources y Prompts\n",
    "====================================================\n",
    "\n",
    "El Model Context Protocol (MCP) organiza la interacción entre modelos de lenguaje, aplicaciones y usuarios en tres componentes esenciales, cada uno actuando en un nivel diferente del ecosistema de IA. La imagen proporcionada ilustra cómo estos elementos se conectan y fluyen dentro de una arquitectura típica MCP.\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    Tools --> LLM\n",
    "    Resources --> Aplicación\n",
    "    Prompts --> Usuario\n",
    "\n",
    "    style LLM fill:transparent,stroke-width:0\n",
    "    style Aplicación fill:transparent,stroke-width:0\n",
    "    style Usuario fill:transparent,stroke-width:0\n",
    "\n",
    "```\n",
    "\n",
    "**Tools (Herramientas)**\n",
    "\n",
    "Las tools son funciones o acciones que el modelo de lenguaje (LLM) puede invocar directamente. Están diseñadas para que el modelo ejecute tareas externas como consultar una API, modificar una base de datos o realizar cálculos.\n",
    "\n",
    "- Ejemplo: El LLM llama a una tool para buscar información en una base de datos de clientes o para enviar un correo electrónico.\n",
    "\n",
    "**Resources (Recursos)**\n",
    "\n",
    "Los resources representan datos estructurados que la aplicación expone al LLM. Son gestionados y controlados por la propia aplicación, y sirven como entradas de solo lectura, similares a endpoints GET en una API REST. Incluyen archivos, logs, respuestas de APIs o cualquier fuente de datos relevante.\n",
    "\n",
    "- Ejemplo: La aplicación expone logs recientes, archivos de configuración o información de usuario como recursos para que el modelo los utilice al responder una consulta.\n",
    "\n",
    "**Prompts (Plantillas)**\n",
    "\n",
    "Los prompts son plantillas reutilizables y predefinidas que estructuran las interacciones entre el usuario y el modelo. Facilitan la estandarización y reutilización de tareas comunes.\n",
    "\n",
    "- Ejemplo: Un usuario selecciona el prompt \"Analizar logs y código\", que solicita los archivos y logs relevantes como argumentos, y guía al modelo a través de un flujo de análisis estructurado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2852a889",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo, se muestra cómo crear un servidor MCP que expone tools, resources y prompts. Los resources pueden recibir parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb3a3dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/03_RessourcesPromptsTools\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37380090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 25_MCP/03_RessourcesPromptsTools/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/03_RessourcesPromptsTools/server.py\"\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "from mcp.server.fastmcp.prompts import base\n",
    "\n",
    "mcp = FastMCP(\"Recipe-Stateless\", stateless_http=True)\n",
    "\n",
    "_FAKE_DB = {\n",
    "    \"chili_con_carne\": \"Chili con Carne\\n• Beans\\n• Ground meat\\n• Chili\\n…\",\n",
    "    \"pancakes\": \"Pancakes\\n• Flour\\n• Milk\\n• Eggs\\n…\",\n",
    "}\n",
    "\n",
    "\n",
    "@mcp.resource(\"recipes://list\")\n",
    "def list_recipes() -> str:\n",
    "    \"\"\"Returns a comma-separated list of all available recipes.\"\"\"\n",
    "    return \", \".join(sorted(_FAKE_DB))\n",
    "\n",
    "\n",
    "@mcp.resource(\"recipe://{dish}\")\n",
    "def get_recipe(dish: str) -> str:\n",
    "    \"\"\"Returns the recipe for the specified dish.\"\"\"\n",
    "    return _FAKE_DB.get(dish, f\"No recipe found for {dish!r}.\")\n",
    "\n",
    "\n",
    "@mcp.tool(description=\"Doubles an integer.\")\n",
    "def double(n: int) -> int:\n",
    "    return n * 2\n",
    "\n",
    "\n",
    "@mcp.prompt()\n",
    "def review_recipe(recipe: str) -> list[base.Message]:\n",
    "    return [\n",
    "        base.UserMessage(\"Please review this recipe:\"),\n",
    "        base.UserMessage(recipe),\n",
    "    ]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e0cc1",
   "metadata": {},
   "source": [
    "El cliente permite listar las tools, resources y prompts disponibles y utilizarlos. Observe que cuando el listado de resources no incluye los parametrizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a8bc78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/03_RessourcesPromptsTools/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/03_RessourcesPromptsTools/client.py\"\n",
    "import asyncio\n",
    "\n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "\n",
    "SERVER = \"http://127.0.0.1:8000/mcp/\"\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    async with streamablehttp_client(SERVER) as (read, write, _):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            resources = await session.list_resources()\n",
    "            print(\"Resources:\", [r.uri for r in resources.resources])\n",
    "\n",
    "            tools = await session.list_tools()\n",
    "            print(\"Tools:\", [t.name for t in tools.tools])\n",
    "\n",
    "            prompts = await session.list_prompts()\n",
    "            print(\"Prompts:\", prompts.prompts)\n",
    "\n",
    "            recipe_response = await session.read_resource(\"recipe://chili_con_carne\")\n",
    "            recipe_text = recipe_response.contents[0].text\n",
    "            print(\"\\nRecipe:\\n\", recipe_text)\n",
    "\n",
    "            doubled_response = await session.call_tool(\"double\", {\"n\": 21})\n",
    "            doubled_value = doubled_response.content[0].text\n",
    "            print(f\"\\n21 doubled -> {doubled_value}\")\n",
    "\n",
    "            prompt_response = await session.get_prompt(\n",
    "                \"review_recipe\",\n",
    "                {\"recipe\": recipe_text},\n",
    "            )\n",
    "            print(\"\\nPrompt messages:\")\n",
    "            for message in prompt_response.messages:\n",
    "                print(f\"[{message.role}] {message.content.text}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb0959",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "El contexto en MCP permite que el servidor comunique información al cliente durante la ejecución de una solicitud. Esto es útil para proporcionar datos adicionales o resultados intermedios que el cliente puede necesitar para completar la tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399b454",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo, el servidor simula el procesamiento de una lista de elementos y la comunicación al cliente durante la ejecución de una solicitud. Observe que el cliente recibe dos tipos de mensajes: uno de tipo log y otro de tipo progress.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1e536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/04_Context\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a240fb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/04_Context/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/04_Context/server.py\"\n",
    "import asyncio\n",
    "\n",
    "from mcp.server.fastmcp import Context, FastMCP\n",
    "\n",
    "mcp = FastMCP(\n",
    "    name=\"ProgressDemoServer\",\n",
    "    stateless_http=False,\n",
    ")\n",
    "\n",
    "\n",
    "@mcp.tool(\n",
    "    name=\"process_items\", description=\"Processes a list of items with progress updates\"\n",
    ")\n",
    "async def process_items(items: list[str], ctx: Context) -> list[str]:\n",
    "    total = len(items)\n",
    "    results: list[str] = []\n",
    "    for i, item in enumerate(items, start=1):\n",
    "        await ctx.info(f\"Processing item {i}/{total}: {item}\")\n",
    "        await ctx.report_progress(progress=i, total=total)\n",
    "        await asyncio.sleep(0.5)\n",
    "        results.append(item.upper())\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed183a",
   "metadata": {},
   "source": [
    "El cliente usa un `handler` para cada uno de los tipos de mensajes enviados por el servidor. Observe también que se ha usado el paquete `fastmcp` en lugar de `mcp`, ya que no se ha conseguido que el paquete `mcp` funcione correctamente con context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dac07dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/04_Context/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/04_Context/client.py\"\n",
    "import asyncio\n",
    "\n",
    "import mcp.types as types\n",
    "from fastmcp import Client\n",
    "from fastmcp.client.logging import LogMessage\n",
    "from fastmcp.client.transports import StreamableHttpTransport\n",
    "\n",
    "\n",
    "async def message_handler(msg):\n",
    "    if not isinstance(msg, types.ServerNotification):\n",
    "        return\n",
    "\n",
    "    root = msg.root\n",
    "    if isinstance(root, types.ProgressNotification):\n",
    "        p = root.params\n",
    "        print(f\"[Progress] {p.progress}/{p.total or '?'}\")\n",
    "\n",
    "\n",
    "async def log_handler(params: LogMessage):\n",
    "    level = params.level.upper()\n",
    "    print(f\"[Log – {level}] {params.data}\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    transport = StreamableHttpTransport(url=\"http://127.0.0.1:8000/mcp/\")\n",
    "    client = Client(transport, message_handler=message_handler, log_handler=log_handler)\n",
    "\n",
    "    async with client:\n",
    "        tools = await client.list_tools()\n",
    "        print(\"→ Available tools:\", [t.name for t in tools])\n",
    "\n",
    "        print(\"→ Calling process_items…\")\n",
    "        items = [\"one\", \"two\", \"three\", \"four\", \"five\"]\n",
    "        result = await client.call_tool(\"process_items\", {\"items\": items})\n",
    "        processed = [c.text for c in result]\n",
    "        print(\"→ Result:\", processed)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7546d2f",
   "metadata": {},
   "source": [
    "### Tools dinámicas\n",
    "\n",
    "En ocasiones, es necesario que el servidor MCP pueda exponer tools dinámicamente, es decir, que el cliente pueda solicitar al servidor que le envíe una tool específica en lugar de tener que conocerla de antemano. Esto es útil cuando las tools dependen de datos específicos o del contexto de la solicitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b1f5a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/05_Discovery\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0580f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/05_Discovery/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/05_Discovery/server.py\"\n",
    "import asyncio\n",
    "import re\n",
    "from fastmcp.tools import Tool\n",
    "from typing import Callable\n",
    "from fastmcp import Context, FastMCP\n",
    "\n",
    "mcp = FastMCP(name=\"Dynamic-Tool-Router Demo\")\n",
    "\n",
    "\n",
    "async def to_upper(text: str) -> str:\n",
    "    return text.upper()\n",
    "\n",
    "\n",
    "async def count_words(text: str) -> int:\n",
    "    await asyncio.sleep(0)\n",
    "    return len(re.findall(r\"\\w+\", text))\n",
    "\n",
    "\n",
    "TOOLS: dict[str, tuple[Callable, str, str]] = {\n",
    "    \"uppercase\": (to_upper, \"upper_tool\", \"Convert text to uppercase.\"),\n",
    "    \"wordcount\": (count_words, \"wordcount_tool\", \"Count words in the text.\"),\n",
    "}\n",
    "\n",
    "\n",
    "def classify(text: str) -> str | None:\n",
    "    if re.fullmatch(r\"[A-ZÄÖÜÊẞ ]+\", text):\n",
    "        return \"wordcount\"\n",
    "    if \"words\" in text.lower() or \"count\" in text.lower():\n",
    "        return \"wordcount\"\n",
    "    if text.islower() or \"upper\" in text.lower():\n",
    "        return \"uppercase\"\n",
    "    return None\n",
    "\n",
    "\n",
    "@mcp.tool(\n",
    "    name=\"router\",\n",
    "    description=\"Classifies text, registers the appropriate tool, executes it, and returns the result.\",\n",
    ")\n",
    "async def router(text: str, ctx: Context):\n",
    "    category = classify(text) or \"uppercase\"\n",
    "    fn, tool_name, desc = TOOLS[category]\n",
    "\n",
    "    # >= 2.7.0\n",
    "    new_tool = Tool.from_function(fn, name=tool_name, description=desc)\n",
    "    ctx.fastmcp.add_tool(new_tool)\n",
    "\n",
    "    # ctx.fastmcp.add_tool(fn, name=tool_name, description=desc) # before 2.7.0\n",
    "    result = await fn(text)\n",
    "    await ctx.info(f\"Result from {tool_name}: {result!r}\")\n",
    "    # await ctx.fastmcp.remove_tool(tool_name)  # remove the tool again if desired\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df4315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools BEFORE : ['router', 'upper_tool']\n",
      "Response   : [TextContent(type='text', text='PLEASE MAKE THIS UPPER CASE', annotations=None)]\n",
      "Tools AFTER  : ['router', 'upper_tool']\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/05_Discovery/client.py\"\n",
    "import asyncio\n",
    "from fastmcp import Client\n",
    "from fastmcp.client.transports import StreamableHttpTransport\n",
    "\n",
    "async def main():\n",
    "    async with Client(StreamableHttpTransport(\"http://127.0.0.1:8000/mcp/\")) as c:\n",
    "        print(\"Tools BEFORE :\", [t.name for t in await c.list_tools()])\n",
    "        response = await c.call_tool(\"router\", {\"text\": \"please make this upper CASE\"})\n",
    "        print(\"Response   :\", response)\n",
    "        print(\"Tools AFTER  :\", [t.name for t in await c.list_tools()])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48428edd",
   "metadata": {},
   "source": [
    "### Integración con LangChain\n",
    "\n",
    "Un agente de LangChain puede usar las tools de un servidor MCP como si fueran tools de LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1361aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/08_LangChain_MCP\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8315226e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/08_LangChain_MCP/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/08_LangChain_MCP/server.py\"\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(name=\"WeatherServer\", stateless_http=True)\n",
    "\n",
    "\n",
    "@mcp.tool(\n",
    "    name=\"get_weather\",\n",
    "    description=\"Returns a weather description for a given city\",\n",
    ")\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        city (str): Name of the city\n",
    "    Returns:\n",
    "        str: Description of the current weather (mock data)\n",
    "    \"\"\"\n",
    "    return \"Sunny, 22°C\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\", host=\"127.0.0.1\", port=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886703db",
   "metadata": {},
   "source": [
    "Podríamos haber guardado el cliente como hemos hecho en los anteriores ejemplos, aunque en este caso se ha preferido ejecutarlo directamente desde Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae5fe1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/surtich/projects/IA para desarrolladores/.env\n",
      "Human: ¿Cuál es el clima en Madrid?\n",
      "AI calls: [{'name': 'get_weather', 'args': {'city': 'Madrid'}, 'id': '7af79f6d-b491-4aed-a06a-4951157907dc', 'type': 'tool_call'}]\n",
      "Tool: Sunny, 22°C\n",
      "AI: El clima en Madrid es soleado, con una temperatura de 22°C.\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "# Busca el archivo .env (o el que especifiques) en el directorio actual y padres\n",
    "dotenv_path = dotenv.find_dotenv()\n",
    "print(dotenv_path)  # Imprime la ruta completa al archivo encontrado\n",
    "\n",
    "# Carga las variables de entorno desde ese archivo\n",
    "dotenv.load_dotenv(dotenv_path)\n",
    "\n",
    "async def main():\n",
    "    client = MultiServerMCPClient(\n",
    "        {\n",
    "            \"weather\": {\n",
    "                \"transport\": \"streamable_http\",\n",
    "                \"url\": \"http://127.0.0.1:3000/mcp/\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    model = ChatGoogleGenerativeAI(\n",
    "       model=\"gemini-2.5-flash\",\n",
    "        api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    )\n",
    "    tools = await client.get_tools()\n",
    "    agent_executor = create_react_agent(model, tools)\n",
    "    messages = await agent_executor.ainvoke({\"messages\": [\"¿Cuál es el clima en Madrid?\"]})\n",
    "    for message in messages[\"messages\"]:\n",
    "        if isinstance(message, AIMessage):\n",
    "            if message.tool_calls:\n",
    "                print(f\"AI calls: {message.tool_calls}\")\n",
    "            else:\n",
    "                print(f\"AI: {message.content}\")\n",
    "        elif isinstance(message, HumanMessage):\n",
    "            print(f\"Human: {message.content}\")\n",
    "        elif isinstance(message, ToolMessage):\n",
    "            print(f\"Tool: {message.content}\")\n",
    "        else:\n",
    "            print(f\"Message: {message.content}\")\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd89714",
   "metadata": {},
   "source": [
    "### Integración con OpenAI SDK Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "757a52f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "El tiempo en Madrid es soleado, 22°C."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from agents import Agent, ModelSettings, OpenAIChatCompletionsModel, Runner\n",
    "from agents.mcp import MCPServerStreamableHttp\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "chat_client = AsyncOpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "chat_model = OpenAIChatCompletionsModel(model=\"gemini-2.5-flash\", openai_client=chat_client)\n",
    "\n",
    "async with MCPServerStreamableHttp(    name=\"weather\",\n",
    "    params={\"url\": \"http://127.0.0.1:3000/mcp\"}\n",
    ") as weather_server:\n",
    "\n",
    "    chat_agent = Agent(\n",
    "        name=\"Agente MCP\",\n",
    "        mcp_servers=[weather_server],\n",
    "        model=chat_model,\n",
    "        model_settings=ModelSettings(tool_choice=\"required\"),\n",
    "    )\n",
    "\n",
    "    result = await Runner.run(chat_agent, \"¿Qué tiempo hace en Madrid?\")\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b2694",
   "metadata": {},
   "source": [
    "### Autenticación con OAuth2\n",
    "\n",
    "Los servidores MCP permiten autenticación de clientes MCP utilizando el protocolo OAuth2. La autenticación se hace a nivel de cliente, no de usuario. Para ello se requiere un servidor OAuth de autentificación (GitHub, Google, auth0, ...). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f927e27b",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant Cliente as 🤖 Cliente\n",
    "    participant ServidorAuth as Servidor de Autorización\n",
    "    participant ServidorMCP as Servidor MCP\n",
    "\n",
    "    Cliente->>ServidorAuth: 1. Solicita token de acceso\n",
    "    ServidorAuth-->>Cliente: 2. Devuelve JWT (token)\n",
    "    Cliente->>ServidorMCP: 3. Usa token en cabecera HTTP para llamar a la tool\n",
    "    ServidorMCP->>ServidorAuth: 4. Valida el token (incluyendo \"scope\")\n",
    "    ServidorMCP-->>Cliente: 5. El cliente recibe la respuesta del servidor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb7243",
   "metadata": {},
   "source": [
    "Para registrar una nueva API y aplicación cliente en Auth0:\n",
    "\n",
    "1.- Registrarse e ir al [`Dashboard`](https://manage.auth0.com/dashboard) de Auth0.\n",
    "2.- Pulsar sobre `Applications` en el menú de la izquierda.\n",
    "3.- Pulsar sobre `APIs`.\n",
    "4.- Pulsar sobre `+ Create API`.\n",
    "5.- Introducir un nombre y una descripción para la API.\n",
    "6.- En `Identifier`, introducir: `http://localhost:8000/mcp`.\n",
    "7.- Pulsar  sobre `Create`.\n",
    "8.- Pulsar sobre `Permissions`.\n",
    "9.- Añadir un nuevo permiso con el nombre `read:add` y la descripción `Permite usar tool read del servidor MCP`.\n",
    "10.- Pulsar sobre `Machine to Machine Applications`.\n",
    "11.- Seleccionar el permiso y pulsar `Update` y `Continue`.\n",
    "12.- Pulsar sobre `Applications` en el menú de la izquierda.\n",
    "13.- Seleccionar la aplicación que se ha creado.\n",
    "14.- Copiar `DOMAIN`, `Client ID` y `Client Secret` que se han generado en el fichero `.env` con los nombres de variables `AUTH0_DOMAIN`, `AUTH0_CLIENT_ID` y `AUTH0_CLIENT_SECRET`, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4136950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/09_Authorization\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7442866f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/09_Authorization/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/09_Authorization/server.py\"\n",
    "import os\n",
    "\n",
    "from fastmcp import FastMCP\n",
    "from fastmcp.server.auth.providers.bearer import BearerAuthProvider\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "AUTH0_DOMAIN = os.environ[\"AUTH0_DOMAIN\"]\n",
    "API_AUDIENCE = os.environ.get(\"API_AUDIENCE\", \"http://localhost:8000/mcp\")\n",
    "REQUIRED_SCOPES = [\"read:add\"]\n",
    "\n",
    "auth = BearerAuthProvider(\n",
    "    jwks_uri=f\"{AUTH0_DOMAIN.rstrip('/')}/.well-known/jwks.json\",\n",
    "    issuer=AUTH0_DOMAIN.rstrip(\"/\") + \"/\",\n",
    "    audience=API_AUDIENCE,\n",
    "    required_scopes=REQUIRED_SCOPES,\n",
    ")\n",
    "\n",
    "mcp = FastMCP(\n",
    "    name=\"SecureAddServer\",\n",
    "    stateless_http=True,\n",
    "    auth=auth,\n",
    ")\n",
    "\n",
    "\n",
    "@mcp.tool(description=\"Add two integers\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\", host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8874279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/09_Authorization/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/09_Authorization/client.py\"\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "import httpx\n",
    "from fastmcp import Client\n",
    "from fastmcp.client.transports import StreamableHttpTransport\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv \n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "AUTH0_DOMAIN = os.environ[\"AUTH0_DOMAIN\"]\n",
    "AUTH0_CLIENT_ID = os.environ[\"AUTH0_CLIENT_ID\"]\n",
    "AUTH0_CLIENT_SECRET = os.environ[\"AUTH0_CLIENT_SECRET\"]\n",
    "API_AUDIENCE = \"http://localhost:8000/mcp\"\n",
    "\n",
    "async def get_auth0_token() -> str:\n",
    "    \"\"\"\n",
    "    Request an access token from Auth0 using the Client Credentials Grant.\n",
    "    \"\"\"\n",
    "    token_url = f\"{AUTH0_DOMAIN}/oauth/token\"\n",
    "    payload = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": AUTH0_CLIENT_ID,\n",
    "        \"client_secret\": AUTH0_CLIENT_SECRET,\n",
    "        \"audience\": API_AUDIENCE,\n",
    "    }\n",
    "    async with httpx.AsyncClient() as http:\n",
    "        response = await http.post(token_url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data[\"access_token\"]\n",
    "\n",
    "\n",
    "async def main():\n",
    "    token = await get_auth0_token()\n",
    "    print(\"Got Auth0 token:\", token)\n",
    "\n",
    "    transport = StreamableHttpTransport(\n",
    "        url=API_AUDIENCE, headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "    )\n",
    "\n",
    "    client = Client(transport)\n",
    "    async with client:\n",
    "        result = await client.call_tool(\"add\", {\"a\": 5, \"b\": 7})\n",
    "        print(\"5 + 7 =\", result[0].text)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e71ae",
   "metadata": {},
   "source": [
    "Se puede probar desde el inspector de MCP añadiendo el Bearer Token en la configuración del inspector. Para obtener el token, en el `Dashboard` de Auth0, pulsar sobre `Applications` y luego sobre selección la aplicación; pulsar sobre `Quickstart` y con la pestaña `CURL` seleccionada, pulsar `Get Token`. Copiar el token que se genera y pegarlo en el inspector en la cada `Bearer` (pulsar `Authentication` para ver la caja)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a608af",
   "metadata": {},
   "source": [
    "### Integración con FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38216105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"25_MCP/10_Fastapi_Integration\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb68575",
   "metadata": {},
   "source": [
    "Observe que se puede definir endpoints de FastAPI y tools de MCP. Los endpoints de FastAPI se usan como `tools` de MCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96481387",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"25_MCP/10_Fastapi_Integration/server.py\"\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastmcp import FastMCP\n",
    "from pydantic import BaseModel\n",
    "\n",
    "app = FastAPI(title=\"Product API\")\n",
    "_products: dict[int, dict] = {}\n",
    "\n",
    "class Product(BaseModel):\n",
    "    name: str\n",
    "    price: float\n",
    "\n",
    "@app.get(\"/products\")\n",
    "def list_products():\n",
    "    \"\"\"List all products\"\"\"\n",
    "    return list(_products.values())\n",
    "\n",
    "@app.get(\"/products/{product_id}\")\n",
    "def get_product(product_id: int):\n",
    "    \"\"\"Get a product by its ID\"\"\"\n",
    "    if product_id not in _products:\n",
    "        raise HTTPException(status_code=404, detail=\"Product not found\")\n",
    "    return _products[product_id]\n",
    "\n",
    "@app.post(\"/products\")\n",
    "def create_product(p: Product):\n",
    "    \"\"\"Create a new product\"\"\"\n",
    "    new_id = len(_products) + 1\n",
    "    _products[new_id] = {\"id\": new_id, **p.model_dump()}\n",
    "    return _products[new_id]\n",
    "\n",
    "mcp = FastMCP.from_fastapi(app=app, name=\"ProductMCP\")\n",
    "\n",
    "@mcp.tool(description=\"Add two integers\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\", host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5b215dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/10_Fastapi_Integration/client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/10_Fastapi_Integration/client.py\"\n",
    "import asyncio\n",
    "from fastmcp import Client\n",
    "from fastmcp.client.transports import StreamableHttpTransport\n",
    "\n",
    "SERVER = \"http://127.0.0.1:8000/mcp/\"\n",
    "\n",
    "\n",
    "def section(title: str):\n",
    "    print(f\"\\n{'=' * 10} {title} {'=' * 10}\")\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    async with Client(StreamableHttpTransport(SERVER)) as session:\n",
    "        \n",
    "        tools = await session.list_tools()\n",
    "        section(\"Available Tools\")\n",
    "        for tool in tools:\n",
    "            print(f\"Tool Name: {tool.name}\")\n",
    "        \n",
    "        all_products = await session.call_tool(tools[0].name)\n",
    "        section(\"All Products (Before)\")\n",
    "        print(all_products)\n",
    "\n",
    "\n",
    "        create_tool_name = tools[1].name\n",
    "\n",
    "        section(f\"Calling Tool: {create_tool_name}\")\n",
    "        created = await session.call_tool(\n",
    "            create_tool_name,\n",
    "            {\"name\": \"Widget\", \"price\": 19.99},\n",
    "        )\n",
    "        print(\"Created product:\", created[0].text)\n",
    "\n",
    "        all_products = await session.call_tool(tools[0].name)\n",
    "        section(\"All Products (After)\")\n",
    "        print(all_products)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad833f",
   "metadata": {},
   "source": [
    "Otra forma de integrar FastAPI con MCP se muestra en el siguiente código. En este caso, los endpoint de FastAPI se sirven desde fuera de MCP. MCP está montado en `http://localhost:8000/mcp-server/mcp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c39a8d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting 25_MCP/10_Fastapi_Integration/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"25_MCP/10_Fastapi_Integration/server.py\"\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastmcp import FastMCP\n",
    "from pydantic import BaseModel\n",
    "\n",
    "_products: dict[int, dict] = {}\n",
    "\n",
    "mcp = FastMCP(\"AddServer\", stateless_http=True)\n",
    "mcp_app = mcp.http_app(path=\"/mcp\")\n",
    "app = FastAPI(lifespan=mcp_app.router.lifespan_context)\n",
    "app.mount(\"/mcp-server\", mcp_app)\n",
    "\n",
    "class Product(BaseModel):\n",
    "    name: str\n",
    "    price: float\n",
    "\n",
    "\n",
    "@app.get(\"/products\")\n",
    "def list_products():\n",
    "    \"\"\"List all products\"\"\"\n",
    "    return list(_products.values())\n",
    "\n",
    "\n",
    "@app.get(\"/products/{product_id}\")\n",
    "def get_product(product_id: int):\n",
    "    \"\"\"Get a product by its ID\"\"\"\n",
    "    if product_id not in _products:\n",
    "        raise HTTPException(status_code=404, detail=\"Product not found\")\n",
    "    return _products[product_id]\n",
    "\n",
    "\n",
    "@app.post(\"/products\")\n",
    "def create_product(p: Product):\n",
    "    \"\"\"Create a new product\"\"\"\n",
    "    new_id = len(_products) + 1\n",
    "    _products[new_id] = {\"id\": new_id, **p.model_dump()}\n",
    "    return _products[new_id]\n",
    "\n",
    "\n",
    "@mcp.tool(description=\"Add two integers\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app=app, host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e380c27",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia-para-desarrolladores",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2629f0c",
   "metadata": {},
   "source": [
    "### Tools\n",
    "\n",
    "Una `Tool`  en el contexto de un LLM es una **función externa o capacidad específica que un LLM puede \"llamar\" o \"utilizar\" para extender sus propias habilidades e interactuar con el mundo real o con sistemas externos.**\n",
    "\n",
    "Los LLM son geniales para generar texto, comprender el lenguaje y razonar sobre información con la que fueron entrenados. Sin embargo, por sí solos, tienen limitaciones importantes:\n",
    "\n",
    "* **No acceden a información en tiempo real**: Su conocimiento está limitado a la fecha de su último entrenamiento. No pueden buscar en Google ahora mismo.\n",
    "* **No realizan acciones**: No pueden ejecutar código, enviar correos electrónicos o interactuar con bases de datos.\n",
    "* **No son siempre precisos en tareas estructuradas**: Aunque pueden generar código, no siempre garantizan su corrección matemática o lógica.\n",
    "\n",
    "Aquí es donde las herramientas se vuelven cruciales.\n",
    "\n",
    "**¿Cómo Funcionan las Llamadas a Herramientas (Tool Calling)?**\n",
    "\n",
    "Una \"tool\" es, en esencia, una **función predefinida** (escrita por el como desarrollador) que se le \"presenta\" al LLM. Cuando el LLM recibe una pregunta o una tarea que requiere una capacidad que no tiene inherentemente, puede \"decidir\" que necesita usar una de estas herramientas.\n",
    "\n",
    "En esta práctica aprenderemos a usar `Tools` con un sencillo ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ecec5",
   "metadata": {},
   "source": [
    "Realizamos los `imports` y creamos una instancia de la API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8f3820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9505e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6865049",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gemini-2.0-flash\"\n",
    "openai = OpenAI(base_url=\"https://generativelanguage.googleapis.com/v1beta\", api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c692c9",
   "metadata": {},
   "source": [
    "Vamos a preguntar al modelo por la fecha actual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30c8e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En este momento, en Madrid (España), son las 13:16 del jueves, 2 de mayo de 2024.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    " model=MODEL,\n",
    " messages=[{\"role\": \"user\", \"content\": \"Dime la fecha y hora actual en Madrid (España)\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a281d18",
   "metadata": {},
   "source": [
    "Vemos que el modelo da una respuesta incorrecta. Esto es porque el modelo no es capaz de hacer una búsqueda en Google.\n",
    "\n",
    "La API de OpenAI para tools no es compatible con Google Gemini y tenemos que usar directamente la librería de Google Gemini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff9c872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La fecha y hora actual en Madrid, España, son martes, 24 de junio de 2025, a las 23:04 (11:04 PM).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai.types import Tool, GenerateContentConfig, GoogleSearch\n",
    "\n",
    "# Only run this block for Gemini Developer API\n",
    "client = genai.Client(api_key=google_api_key)\n",
    "model_id = \"gemini-2.0-flash\"\n",
    "\n",
    "google_search_tool = Tool(\n",
    "    google_search = GoogleSearch()\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=\"¿Cuál es la fecha y hora actual en Madrid (España)?\",\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[google_search_tool],\n",
    "        response_modalities=[\"TEXT\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "for each in response.candidates[0].content.parts:\n",
    "    print(each.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
